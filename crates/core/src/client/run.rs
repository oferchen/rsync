//! crates/core/src/client/run.rs

use std::ffi::OsStr;
use std::fs::{File, OpenOptions};
use std::io::{BufReader, BufWriter, Write};
use std::path::{Path, PathBuf};
use std::sync::{Arc, Mutex};
use std::time::Duration;

#[cfg(feature = "tracing")]
use tracing::instrument;

use engine::batch::{BatchReader, BatchWriter};
use engine::local_copy::{
    DirMergeRule, ExcludeIfPresentRule, FilterProgram, FilterProgramEntry, LocalCopyExecution,
    LocalCopyOptions, LocalCopyPlan, ReferenceDirectory as EngineReferenceDirectory,
    ReferenceDirectoryKind as EngineReferenceDirectoryKind,
};
use filters::FilterRule as EngineFilterRule;

use super::config::{
    ClientConfig, DeleteMode, FilterRuleKind, FilterRuleSpec, ReferenceDirectoryKind,
};
use super::error::{
    ClientError, compile_filter_error, map_local_copy_error, missing_operands_error,
};
use super::fallback::RemoteFallbackContext;
use super::outcome::ClientOutcome;
use super::progress::{ClientProgressForwarder, ClientProgressObserver};
use super::remote;
use super::summary::ClientSummary;

/// Runs the client orchestration using the provided configuration.
///
/// The helper executes the local copy engine for local transfers, or the
/// native SSH transport for remote transfers. Both paths return a summary
/// of the work performed.
#[cfg_attr(feature = "tracing", instrument(skip(config)))]
pub fn run_client(config: ClientConfig) -> Result<ClientSummary, ClientError> {
    run_client_internal(config, None)
}

/// Runs the client orchestration while reporting progress events.
///
/// When an observer is supplied the transfer emits progress updates mirroring
/// the behaviour of `--info=progress2`.
#[cfg_attr(feature = "tracing", instrument(skip(config, observer)))]
pub fn run_client_with_observer(
    config: ClientConfig,
    observer: Option<&mut dyn ClientProgressObserver>,
) -> Result<ClientSummary, ClientError> {
    run_client_internal(config, observer)
}

/// Executes the client flow, delegating to a fallback `rsync` binary when provided.
///
/// The caller may supply a [`RemoteFallbackContext`] that describes how to invoke
/// an upstream `rsync` binary for remote transfers while the native engine
/// evolves.
#[cfg_attr(feature = "tracing", instrument(skip(config, observer, _fallback)))]
pub fn run_client_or_fallback<Out, Err>(
    config: ClientConfig,
    observer: Option<&mut dyn ClientProgressObserver>,
    _fallback: Option<RemoteFallbackContext<'_, Out, Err>>,
) -> Result<ClientOutcome, ClientError>
where
    Out: Write,
    Err: Write,
{
    run_client_internal(config, observer).map(|summary| ClientOutcome::Local(Box::new(summary)))
}

#[cfg_attr(
    feature = "tracing",
    instrument(skip(config, observer), name = "client_internal")
)]
fn run_client_internal(
    config: ClientConfig,
    observer: Option<&mut dyn ClientProgressObserver>,
) -> Result<ClientSummary, ClientError> {
    if !config.has_transfer_request() {
        return Err(missing_operands_error());
    }

    // Handle batch mode configuration
    let batch_writer = if let Some(batch_cfg) = config.batch_config() {
        if batch_cfg.is_read_mode() {
            // Replay the batch file instead of performing a normal transfer
            return replay_batch(batch_cfg, &config);
        }

        // For write modes, create the BatchWriter
        match BatchWriter::new((*batch_cfg).clone()) {
            Ok(writer) => {
                // Wrap in Arc<Mutex<...>> for thread-safe shared access
                Some(Arc::new(Mutex::new(writer)))
            }
            Err(e) => {
                use crate::message::Role;
                use crate::rsync_error;
                let msg = format!(
                    "failed to create batch file '{}': {}",
                    batch_cfg.batch_file_path().display(),
                    e
                );
                return Err(ClientError::new(
                    1,
                    rsync_error!(1, "{}", msg).with_role(Role::Client),
                ));
            }
        }
    } else {
        None
    };

    // Check for remote operands and dispatch appropriately
    let has_daemon_url = config.transfer_args().iter().any(|arg| {
        arg.to_string_lossy().starts_with("rsync://") || arg.to_string_lossy().contains("::")
    });

    if has_daemon_url {
        // Daemon data transfer via rsync:// URLs
        return remote::run_daemon_transfer(&config, observer);
    }

    let has_remote = config
        .transfer_args()
        .iter()
        .any(|arg| remote::operand_is_remote(arg));

    if has_remote {
        return remote::run_ssh_transfer(&config, observer);
    }

    // Local copy path
    let plan = match LocalCopyPlan::from_operands(config.transfer_args()) {
        Ok(plan) => plan,
        Err(error) => return Err(map_local_copy_error(error)),
    };

    // Mirror upstream: validate destination directory access early (main.c:751)
    // This returns FILE_SELECTION error (3) instead of PARTIAL_TRANSFER (23)
    // Check the destination itself if it's a directory, otherwise check its parent
    use std::fs;
    let dest_to_check = if plan.destination().is_dir() {
        plan.destination()
    } else if let Some(parent) = plan.destination().parent() {
        parent
    } else {
        plan.destination()
    };

    // Try to read the directory - this will fail with Permission Denied if not accessible
    if let Err(error) = fs::read_dir(dest_to_check) {
        // Only return FILE_SELECTION error for permission denied
        // Other errors (like NotFound) should proceed normally
        if error.kind() == std::io::ErrorKind::PermissionDenied {
            return Err(super::error::destination_access_error(dest_to_check, error));
        }
    }

    let filter_program = compile_filter_program(config.filter_rules())?;
    let mut options = build_local_copy_options(&config, filter_program);

    // Attach batch writer to options if in batch write mode
    let batch_writer_for_options = if let Some(ref writer) = batch_writer {
        // Write batch header with stream flags before starting transfer
        let batch_flags = engine::batch::BatchFlags {
            recurse: config.recursive(),
            preserve_uid: config.preserve_owner(),
            preserve_gid: config.preserve_group(),
            preserve_links: config.links(),
            preserve_hard_links: config.preserve_hard_links(),
            always_checksum: config.checksum(),
            xfer_dirs: config.dirs(),
            do_compression: config.compress(),
            preserve_xattrs: config.preserve_xattrs(),
            inplace: config.inplace(),
            append: config.append(),
            append_verify: config.append_verify(),
            ..Default::default()
        };

        {
            let mut w = writer.lock().unwrap();
            if let Err(e) = w.write_header(batch_flags) {
                use crate::message::Role;
                use crate::rsync_error;
                let msg = format!("failed to write batch header: {e}");
                return Err(ClientError::new(
                    1,
                    rsync_error!(1, "{}", msg).with_role(Role::Client),
                ));
            }
        }

        Some(writer.clone())
    } else {
        None
    };

    if let Some(ref writer_arc) = batch_writer_for_options {
        options = options.batch_writer(Some(writer_arc.clone()));
    }

    let mode = if config.dry_run() || config.list_only() {
        LocalCopyExecution::DryRun
    } else {
        LocalCopyExecution::Apply
    };

    let collect_events = config.collect_events();

    if collect_events {
        options = options.collect_events(true);
    }

    let mut handler_adapter = observer
        .map(|observer| ClientProgressForwarder::new(observer, &plan, options.clone()))
        .transpose()?;

    let summary = if collect_events {
        plan.execute_with_report_and_handler(
            mode,
            options,
            handler_adapter
                .as_mut()
                .map(ClientProgressForwarder::as_handler_mut),
        )
        .map(ClientSummary::from_report)
    } else {
        plan.execute_with_options_and_handler(
            mode,
            options,
            handler_adapter
                .as_mut()
                .map(ClientProgressForwarder::as_handler_mut),
        )
        .map(ClientSummary::from_summary)
    };

    let summary = summary.map_err(map_local_copy_error)?;

    // Finalize batch file if batch mode was active
    if let Some(ref writer_arc) = batch_writer
        && let Some(batch_cfg) = config.batch_config()
    {
        // Finalize and close the batch file
        {
            let mut writer = writer_arc.lock().unwrap();
            if let Err(e) = writer.flush() {
                use crate::message::Role;
                use crate::rsync_error;
                let msg = format!("failed to flush batch file: {e}");
                return Err(ClientError::new(
                    1,
                    rsync_error!(1, "{}", msg).with_role(Role::Client),
                ));
            }
        } // Drop the lock and BatchWriter will be cleaned up by Drop impl

        // Generate the .sh replay script
        if let Err(e) = engine::batch::script::generate_script(batch_cfg) {
            use crate::message::Role;
            use crate::rsync_error;
            let msg = format!("failed to generate batch script: {e}");
            return Err(ClientError::new(
                1,
                rsync_error!(1, "{}", msg).with_role(Role::Client),
            ));
        }
    }

    Ok(summary)
}

/// Builder for [`LocalCopyOptions`] derived from a [`ClientConfig`] and
/// optional [`FilterProgram`].
///
/// This encapsulates the translation from CLI-facing configuration to
/// engine options using a Builder-style fa√ßade, keeping
/// `build_local_copy_options` small and testable.
struct LocalCopyOptionsBuilder<'a> {
    config: &'a ClientConfig,
    filter_program: Option<FilterProgram>,
}

impl<'a> LocalCopyOptionsBuilder<'a> {
    const fn new(config: &'a ClientConfig, filter_program: Option<FilterProgram>) -> Self {
        Self {
            config,
            filter_program,
        }
    }

    fn build(self) -> LocalCopyOptions {
        let config = self.config;
        let mut options = LocalCopyOptions::default();

        options = self.apply_recursion_and_delete(options, config);
        options = self.apply_core_limits_and_bandwidth(options, config);
        options = self.apply_compression(options, config);
        options = self.apply_metadata_preservation(options, config);
        options = self.apply_behavioral_flags(options, config);
        options = self.apply_paths_and_backups(options, config);
        options = self.apply_time_and_timeout(options, config);
        options = self.apply_reference_directories(options, config);
        options = self.apply_filter_program(options);

        options
    }

    const fn apply_recursion_and_delete(
        &self,
        mut options: LocalCopyOptions,
        config: &ClientConfig,
    ) -> LocalCopyOptions {
        options = options.recursive(config.recursive());

        if config.delete_mode().is_enabled() || config.delete_excluded() {
            options = options.delete(true);
        }

        options = match config.delete_mode() {
            DeleteMode::Before => options.delete_before(true),
            DeleteMode::After => options.delete_after(true),
            DeleteMode::Delay => options.delete_delay(true),
            DeleteMode::During | DeleteMode::Disabled => options,
        };

        options
            .delete_excluded(config.delete_excluded())
            .max_deletions(config.max_delete())
    }

    fn apply_core_limits_and_bandwidth(
        &self,
        options: LocalCopyOptions,
        config: &ClientConfig,
    ) -> LocalCopyOptions {
        options
            .min_file_size(config.min_file_size())
            .max_file_size(config.max_file_size())
            .with_block_size_override(config.block_size_override())
            .remove_source_files(config.remove_source_files())
            .bandwidth_limit(
                config
                    .bandwidth_limit()
                    .map(|limit| limit.bytes_per_second()),
            )
            .bandwidth_burst(
                config
                    .bandwidth_limit()
                    .and_then(|limit| limit.burst_bytes()),
            )
    }

    fn apply_compression(
        &self,
        options: LocalCopyOptions,
        config: &ClientConfig,
    ) -> LocalCopyOptions {
        options
            .with_compression_algorithm(config.compression_algorithm())
            .with_default_compression_level(config.compression_setting().level_or_default())
            .with_skip_compress(config.skip_compress().clone())
            .compress(config.compress())
            .with_compression_level_override(config.compression_level())
    }

    fn apply_metadata_preservation(
        &self,
        mut options: LocalCopyOptions,
        config: &ClientConfig,
    ) -> LocalCopyOptions {
        options = options
            .with_stop_at(config.stop_at())
            .whole_file(config.whole_file())
            .open_noatime(config.open_noatime())
            .owner(config.preserve_owner())
            .with_owner_override(config.owner_override())
            .group(config.preserve_group())
            .with_group_override(config.group_override())
            .with_chmod(config.chmod().cloned())
            .executability(config.preserve_executability())
            .permissions(config.preserve_permissions())
            .times(config.preserve_times())
            .omit_dir_times(config.omit_dir_times())
            .omit_link_times(config.omit_link_times())
            .with_user_mapping(config.user_mapping().cloned())
            .with_group_mapping(config.group_mapping().cloned());

        #[cfg(feature = "acl")]
        {
            options = options.acls(config.preserve_acls());
        }

        // IMPORTANT: LocalCopyOptions::xattrs is only implemented on Unix.
        // Match the engine crate's cfg so Windows builds with the `xattr`
        // feature do not try to call a non-existent method.
        #[cfg(all(feature = "xattr", unix))]
        {
            options = options.xattrs(config.preserve_xattrs());
        }

        options
    }

    fn apply_behavioral_flags(
        &self,
        options: LocalCopyOptions,
        config: &ClientConfig,
    ) -> LocalCopyOptions {
        options
            .checksum(config.checksum())
            .with_checksum_algorithm(config.checksum_signature_algorithm())
            .size_only(config.size_only())
            .ignore_times(config.ignore_times())
            .ignore_existing(config.ignore_existing())
            .existing_only(config.existing_only())
            .ignore_missing_args(config.ignore_missing_args())
            .delete_missing_args(config.delete_missing_args())
            .update(config.update())
            .with_modify_window(config.modify_window_duration())
            .numeric_ids(config.numeric_ids())
            .preallocate(config.preallocate())
            .fsync(config.fsync())
            .hard_links(config.preserve_hard_links())
            .links(config.links())
            .sparse(config.sparse())
            .copy_links(config.copy_links())
            .copy_dirlinks(config.copy_dirlinks())
            .copy_devices_as_files(config.copy_devices())
            .copy_unsafe_links(config.copy_unsafe_links())
            .keep_dirlinks(config.keep_dirlinks())
            .safe_links(config.safe_links())
            .devices(config.preserve_devices())
            .specials(config.preserve_specials())
            .one_file_system(config.one_file_system())
            .relative_paths(config.relative_paths())
            .dirs(config.dirs())
            .implied_dirs(config.implied_dirs())
            .mkpath(config.mkpath())
            .prune_empty_dirs(config.prune_empty_dirs())
            .inplace(config.inplace())
            .append(config.append())
            .append_verify(config.append_verify())
            .partial(config.partial())
            .force_replacements(config.force_replacements())
    }

    fn apply_paths_and_backups(
        &self,
        options: LocalCopyOptions,
        config: &ClientConfig,
    ) -> LocalCopyOptions {
        options
            .with_temp_directory(config.temp_directory().map(|path| path.to_path_buf()))
            .backup(config.backup())
            .with_backup_directory(config.backup_directory().map(|path| path.to_path_buf()))
            .with_backup_suffix(config.backup_suffix().map(OsStr::to_os_string))
            .with_partial_directory(config.partial_directory().map(|path| path.to_path_buf()))
            .delay_updates(config.delay_updates())
            .extend_link_dests(config.link_dest_paths().iter().cloned())
    }

    fn apply_time_and_timeout(
        &self,
        options: LocalCopyOptions,
        config: &ClientConfig,
    ) -> LocalCopyOptions {
        options.with_timeout(
            config
                .timeout()
                .as_seconds()
                .map(|seconds| Duration::from_secs(seconds.get())),
        )
    }

    fn apply_reference_directories(
        &self,
        mut options: LocalCopyOptions,
        config: &ClientConfig,
    ) -> LocalCopyOptions {
        if !config.reference_directories().is_empty() {
            let references = config.reference_directories().iter().map(|reference| {
                let kind = match reference.kind() {
                    ReferenceDirectoryKind::Compare => EngineReferenceDirectoryKind::Compare,
                    ReferenceDirectoryKind::Copy => EngineReferenceDirectoryKind::Copy,
                    ReferenceDirectoryKind::Link => EngineReferenceDirectoryKind::Link,
                };
                EngineReferenceDirectory::new(kind, reference.path().to_path_buf())
            });
            options = options.extend_reference_directories(references);
        }
        options
    }

    fn apply_filter_program(self, options: LocalCopyOptions) -> LocalCopyOptions {
        options.with_filter_program(self.filter_program)
    }
}

/// Builds [`LocalCopyOptions`] reflecting the provided client configuration and optional filter
/// program.
///
/// This helper mirrors the internal wiring used by [`run_client`](super::run_client) so that unit
/// tests can validate the translation layer without re-invoking the entire transfer engine.
#[doc(hidden)]
pub fn build_local_copy_options(
    config: &ClientConfig,
    filter_program: Option<FilterProgram>,
) -> LocalCopyOptions {
    LocalCopyOptionsBuilder::new(config, filter_program).build()
}

fn compile_filter_program(rules: &[FilterRuleSpec]) -> Result<Option<FilterProgram>, ClientError> {
    if rules.is_empty() {
        return Ok(None);
    }

    let mut entries = Vec::new();
    for rule in rules {
        match rule.kind() {
            FilterRuleKind::Include => entries.push(FilterProgramEntry::Rule(
                EngineFilterRule::include(rule.pattern().to_owned())
                    .with_sides(rule.applies_to_sender(), rule.applies_to_receiver())
                    .with_perishable(rule.is_perishable())
                    .with_xattr_only(rule.is_xattr_only()),
            )),
            FilterRuleKind::Exclude => entries.push(FilterProgramEntry::Rule(
                EngineFilterRule::exclude(rule.pattern().to_owned())
                    .with_sides(rule.applies_to_sender(), rule.applies_to_receiver())
                    .with_perishable(rule.is_perishable())
                    .with_xattr_only(rule.is_xattr_only()),
            )),
            FilterRuleKind::Clear => entries.push(FilterProgramEntry::Clear),
            FilterRuleKind::Protect => entries.push(FilterProgramEntry::Rule(
                EngineFilterRule::protect(rule.pattern().to_owned())
                    .with_sides(rule.applies_to_sender(), rule.applies_to_receiver())
                    .with_perishable(rule.is_perishable()),
            )),
            FilterRuleKind::Risk => entries.push(FilterProgramEntry::Rule(
                EngineFilterRule::risk(rule.pattern().to_owned())
                    .with_sides(rule.applies_to_sender(), rule.applies_to_receiver())
                    .with_perishable(rule.is_perishable()),
            )),
            FilterRuleKind::DirMerge => {
                entries.push(FilterProgramEntry::DirMerge(DirMergeRule::new(
                    rule.pattern().to_owned(),
                    rule.dir_merge_options().cloned().unwrap_or_default(),
                )))
            }
            FilterRuleKind::ExcludeIfPresent => entries.push(FilterProgramEntry::ExcludeIfPresent(
                ExcludeIfPresentRule::new(rule.pattern().to_owned()),
            )),
        }
    }

    FilterProgram::new(entries)
        .map(Some)
        .map_err(|error| compile_filter_error(error.pattern(), &error))
}

/// Apply delta operations to a file.
///
/// Takes delta operations from the batch file and applies them to transform
/// the basis file into the target file. This mirrors upstream rsync's batch
/// replay logic.
fn apply_batch_delta_ops(
    basis_path: &Path,
    dest_path: &Path,
    delta_ops: Vec<protocol::wire::delta::DeltaOp>,
    block_length: usize,
) -> Result<(), ClientError> {
    use crate::message::Role;
    use crate::rsync_error;
    use std::io::{Read, Seek, SeekFrom};

    // Open basis file for reading
    let basis_file = File::open(basis_path).map_err(|e| {
        let msg = format!(
            "failed to open basis file '{}': {}",
            basis_path.display(),
            e
        );
        ClientError::new(1, rsync_error!(1, "{}", msg).with_role(Role::Client))
    })?;
    let mut basis = BufReader::new(basis_file);

    // Create output file
    let output_file = OpenOptions::new()
        .write(true)
        .create(true)
        .truncate(true)
        .open(dest_path)
        .map_err(|e| {
            let msg = format!(
                "failed to create output file '{}': {}",
                dest_path.display(),
                e
            );
            ClientError::new(1, rsync_error!(1, "{}", msg).with_role(Role::Client))
        })?;
    let mut output = BufWriter::new(output_file);

    // Apply delta operations directly without signature machinery
    // This is simpler for batch mode since we already have all the operations
    let mut buffer = vec![0u8; 8192];
    for op in delta_ops {
        match op {
            protocol::wire::delta::DeltaOp::Literal(data) => {
                // Write literal data directly
                output.write_all(&data).map_err(|e| {
                    let msg = format!("failed to write literal data: {e}");
                    ClientError::new(1, rsync_error!(1, "{}", msg).with_role(Role::Client))
                })?;
            }
            protocol::wire::delta::DeltaOp::Copy {
                block_index,
                length,
            } => {
                // Calculate offset in basis file
                let offset = u64::from(block_index) * (block_length as u64);

                // Seek to the block position
                basis.seek(SeekFrom::Start(offset)).map_err(|e| {
                    let msg = format!("failed to seek to offset {offset}: {e}");
                    ClientError::new(1, rsync_error!(1, "{}", msg).with_role(Role::Client))
                })?;

                // Copy data from basis to output
                let mut remaining = length as usize;
                while remaining > 0 {
                    let chunk_size = remaining.min(buffer.len());
                    basis.read_exact(&mut buffer[..chunk_size]).map_err(|e| {
                        let msg = format!("failed to read from basis file: {e}");
                        ClientError::new(1, rsync_error!(1, "{}", msg).with_role(Role::Client))
                    })?;
                    output.write_all(&buffer[..chunk_size]).map_err(|e| {
                        let msg = format!("failed to write to output file: {e}");
                        ClientError::new(1, rsync_error!(1, "{}", msg).with_role(Role::Client))
                    })?;
                    remaining -= chunk_size;
                }
            }
        }
    }

    // Flush output
    output.flush().map_err(|e| {
        let msg = format!("failed to flush output file: {e}");
        ClientError::new(1, rsync_error!(1, "{}", msg).with_role(Role::Client))
    })?;

    Ok(())
}

/// Replay a batch file to reconstruct the transfer at the destination.
///
/// This function reads a previously recorded batch file and applies the
/// recorded operations to create/update files in the destination directory.
fn replay_batch(
    batch_cfg: &engine::batch::BatchConfig,
    config: &ClientConfig,
) -> Result<ClientSummary, ClientError> {
    use crate::message::Role;
    use crate::rsync_error;

    // Get destination directory from transfer arguments
    // For batch replay: `oc-rsync --read-batch=FILE destination/`
    let dest_root = if config.transfer_args().is_empty() {
        PathBuf::from(".")
    } else {
        PathBuf::from(&config.transfer_args()[0])
    };

    // Open the batch file for reading
    let mut reader = BatchReader::new((*batch_cfg).clone()).map_err(|e| {
        let msg = format!(
            "failed to open batch file '{}': {}",
            batch_cfg.batch_file_path().display(),
            e
        );
        ClientError::new(1, rsync_error!(1, "{}", msg).with_role(Role::Client))
    })?;

    // Read and validate the batch header
    let flags = reader.read_header().map_err(|e| {
        let msg = format!("failed to read batch header: {e}");
        ClientError::new(1, rsync_error!(1, "{}", msg).with_role(Role::Client))
    })?;

    // Read file entries and apply delta operations
    // Format: Header, FileEntry1, DeltaOps1, FileEntry2, DeltaOps2, ..., EmptyPath
    let mut file_count = 0u64;
    let mut total_size = 0u64;

    while let Some(entry) = reader.read_file_entry().map_err(|e| {
        let msg = format!("failed to read file entry: {e}");
        ClientError::new(1, rsync_error!(1, "{}", msg).with_role(Role::Client))
    })? {
        file_count += 1;
        total_size += entry.size;

        // Log the file being processed
        if config.verbosity() > 0 {
            println!("{}", entry.path);
        }

        // Read all delta operations for this file
        // Note: This reads until EOF, suitable for single-file batches
        // Multi-file batches need more sophisticated boundary detection
        let delta_ops = reader.read_all_delta_ops().map_err(|e| {
            let msg = format!("failed to read delta operations for '{}': {e}", entry.path);
            ClientError::new(1, rsync_error!(1, "{}", msg).with_role(Role::Client))
        })?;

        if config.verbosity() > 0 {
            println!("  {} delta operations", delta_ops.len());
        }

        // Build file path in destination directory
        let dest_path = dest_root.join(&entry.path);

        // For batch replay, the basis file is the existing file at the destination
        // (This is what we're transforming)
        let basis_path = dest_path.clone();

        // Apply delta operations to create/update the file
        // Block length is typically 700 bytes for files ~100KB
        // Implementation note: Upstream rsync calculates block_length dynamically based on
        // file size (see match.c:365, choose_block_size()). For batch mode, this value
        // should ideally be stored in the batch header or calculated from the signature.
        // Current implementation uses a fixed default that works for typical file sizes.
        const DEFAULT_BLOCK_LENGTH: usize = 700;
        apply_batch_delta_ops(&basis_path, &dest_path, delta_ops, DEFAULT_BLOCK_LENGTH)?;
    }

    // Implementation status: Batch mode MVP complete for single-file validation.
    //
    // Full batch mode implementation scope (for future enhancement):
    // 1. Multi-file batch processing:
    //    a. Read delta operations (COPY/LITERAL) for each file from batch
    //    b. Apply operations to destination directory
    //    c. Set file metadata (mode, mtime, uid, gid)
    // 2. Special file handling: directories, symlinks, devices
    // 3. Preservation flag application from batch header
    //
    // Current implementation: Successfully reads and validates batch file format,
    // reports file count and total size, handles single-file delta application.

    // Report what was read
    if flags.recurse {
        eprintln!("Batch mode enabled: recurse");
    }
    eprintln!("Batch replay: {file_count} files ({total_size} bytes total)");

    // Return a summary with the file count
    use engine::local_copy::LocalCopySummary;
    Ok(ClientSummary::from_summary(LocalCopySummary::default()))
}
